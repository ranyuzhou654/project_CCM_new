# CCM因果分析工具箱 v3.0 详细技术文档

## 目录
- [1. 架构设计](#1-架构设计)
- [2. 核心算法详解](#2-核心算法详解)
- [3. 动力学系统实现](#3-动力学系统实现)
- [4. 参数优化策略](#4-参数优化策略)
- [5. 代理数据方法](#5-代理数据方法)
- [6. 可视化系统](#6-可视化系统)
- [7. 数值稳定性保证](#7-数值稳定性保证)
- [8. 性能分析框架](#8-性能分析框架)
- [9. API参考](#9-api参考)

## 1. 架构设计

### 1.1 模块化架构

CCM工具箱采用严格的模块化设计，确保各组件间的松耦合和高内聚：

```
CCM_Analysis_Toolbox/
├── core/                   # 核心算法层
│   ├── ccm.py             # CCM算法和代理方法
│   ├── systems.py         # 动力学系统生成
│   ├── analysis.py        # 分析工作流
│   ├── motifs.py          # 基序分析
│   └── partial_ccm.py     # 偏CCM算法
├── utils/                  # 工具层
│   ├── params.py          # 参数优化
│   └── visualization.py   # 可视化系统
└── main.py                # CLI接口层
```

### 1.2 设计原则

- **分离关注点**: 算法逻辑与数据处理分离
- **可扩展性**: 支持新系统和算法的轻松集成
- **错误处理**: 全面的异常处理和数值稳定性检查
- **性能优化**: 向量化计算和内存高效实现

## 2. 核心算法详解

### 2.1 CCM (收敛交叉映射) 算法

#### 2.1.1 理论基础

CCM基于Takens嵌入定理，通过重构动力学系统的吸引子流形来检测因果关系。核心思想是：如果X因果影响Y，那么X的历史信息应该包含在Y的动力学中。

#### 2.1.2 算法流程

1. **状态空间重构**
   ```python
   def parameters(series, Dim, tau):
       """构建影子流形"""
       L = len(series)
       shadow_length = L - (Dim - 1) * tau
       shadow = np.column_stack([
           series[i * tau : L - (Dim - 1 - i) * tau] 
           for i in range(Dim)
       ])
   ```

2. **最近邻搜索**
   - 使用KD-树或Ball-tree算法寻找最近邻
   - 计算欧氏距离并排序
   
3. **权重计算**
   ```python
   # 指数权重函数
   u = np.exp(-distances / (distances[:, [0]] + epsilon))
   weights = u / np.sum(u, axis=1, keepdims=True)
   ```

4. **预测与相关性计算**
   ```python
   def ccm_pearson(target, weights, indices, shadow_length):
       """使用加权平均预测目标值"""
       predictions = np.sum(weights * target[indices], axis=1)
       actual = target[-shadow_length:]
       return pearsonr(actual, predictions)[0]
   ```

### 2.2 条件传递熵 (CTE)

#### 2.2.1 理论基础

CTE量化在控制变量Z条件下，从变量X到Y的信息流动：

```
CTE_{X→Y|Z} = H(Y_{t+1}|Y_t, Z_t) - H(Y_{t+1}|Y_t, X_t, Z_t)
```

其中H表示条件熵。

#### 2.2.2 计算实现

```python
from pyinform import transferentropy as te

def compute_conditional_te(source, target, condition, k=1, tau=1):
    """计算条件传递熵"""
    # 离散化时间序列
    source_discrete = discretize_series(source)
    target_discrete = discretize_series(target)
    condition_discrete = discretize_series(condition)
    
    # 计算传递熵
    return te.transfer_entropy(
        source_discrete, target_discrete, 
        condition=condition_discrete, k=k
    )
```

### 2.3 偏CCM (Partial CCM)

#### 2.3.1 算法原理

偏CCM控制第三变量的影响，识别直接因果关系：

1. 构建三维影子流形 [X, Y, Z]
2. 在Z固定的条件下计算X→Y的映射强度
3. 使用条件相关系数评估因果强度

#### 2.3.2 实现细节

```python
def partial_ccm(X, Y, Z, Dim, tau):
    """偏CCM实现"""
    # 构建联合影子流形
    joint_shadow = construct_joint_shadow(X, Y, Z, Dim, tau)
    
    # 分层最近邻搜索
    neighbors = find_conditional_neighbors(joint_shadow, condition_var=Z)
    
    # 计算偏相关
    return compute_partial_correlation(X, Y, neighbors)
```

## 3. 动力学系统实现

### 3.1 连续系统

#### 3.1.1 Lorenz系统

经典的混沌动力学系统，展现蝴蝶效应：

```python
def lorenz_system(state, t, sigma=10.0, rho=28.0, beta=8.0/3.0):
    """Lorenz方程组"""
    x, y, z = state
    dxdt = sigma * (y - x)
    dydt = x * (rho - z) - y
    dzdt = x * y - beta * z
    return [dxdt, dydt, dzdt]
```

#### 3.1.2 Rössler系统

另一个著名的混沌吸引子，具有不同的几何结构：

```python
def rossler_system(state, t, a=0.2, b=0.2, c=5.7):
    """Rössler方程组"""
    x, y, z = state
    dxdt = -y - z
    dydt = x + a * y
    dzdt = b + z * (x - c)
    return [dxdt, dydt, dzdt]
```

### 3.2 噪声处理

#### 3.2.1 观测噪声

直接在系统输出上添加高斯白噪声：

```python
def add_observational_noise(signal, noise_level=0.05):
    """添加观测噪声"""
    noise_std = noise_level * np.std(signal)
    noise = np.random.normal(0, noise_std, signal.shape)
    return signal + noise
```

#### 3.2.2 动态噪声 (SDE方法)

使用分步积分方法模拟随机微分方程：

```python
def integrate_with_dynamic_noise(system_func, initial_state, time_points, noise_level):
    """带动态噪声的SDE积分"""
    dt = time_points[1] - time_points[0]
    states = [initial_state]
    
    for i in range(1, len(time_points)):
        # 确定性积分步骤
        current_state = odeint(system_func, states[-1], [0, dt/10])[-1]
        
        # 添加比例噪声
        noise_std = noise_level * np.std(current_state) * np.sqrt(dt)
        noise = np.random.normal(0, noise_std, current_state.shape)
        
        # 更新状态
        next_state = current_state + noise
        states.append(next_state)
    
    return np.array(states)
```

### 3.3 离散系统

#### 3.3.1 Logistic映射

经典的一维混沌映射：

```python
def logistic_map_coupled(num_systems, coupling_matrix, r_values, time_steps):
    """耦合Logistic映射"""
    X = np.zeros((num_systems, time_steps))
    X[:, 0] = np.random.uniform(0.1, 0.9, num_systems)
    
    for t in range(1, time_steps):
        for i in range(num_systems):
            # 自身动力学
            internal_dynamics = r_values[i] * X[i, t-1] * (1 - X[i, t-1])
            
            # 耦合项
            coupling_sum = np.sum([
                coupling_matrix[i, j] * (X[j, t-1] - X[i, t-1])
                for j in range(num_systems) if j != i
            ])
            
            X[i, t] = internal_dynamics + coupling_strength * coupling_sum
    
    return X
```

#### 3.3.2 Hénon映射

二维混沌映射系统：

```python
def henon_map_coupled(num_systems, coupling_matrix, time_steps, a=1.4, b=0.3):
    """耦合Hénon映射"""
    X = np.zeros((num_systems, time_steps))
    Y = np.zeros((num_systems, time_steps))
    
    # 初始条件
    X[:, 0] = np.random.uniform(-1, 1, num_systems)
    Y[:, 0] = np.random.uniform(-1, 1, num_systems)
    
    for t in range(1, time_steps):
        for i in range(num_systems):
            # Hénon映射动力学
            x_new = 1 - a * X[i, t-1]**2 + Y[i, t-1]
            y_new = b * X[i, t-1]
            
            # 耦合修正
            coupling_x = np.sum([
                coupling_matrix[i, j] * (X[j, t-1] - X[i, t-1])
                for j in range(num_systems) if j != i
            ])
            
            X[i, t] = x_new + coupling_strength * coupling_x
            Y[i, t] = y_new
    
    return X, Y
```

## 4. 参数优化策略

### 4.1 平均互信息 (AMI)

#### 4.1.1 理论基础

AMI测量时间序列x(t)和x(t+τ)之间的非线性相关性：

```
AMI(τ) = ∑∑ p(xi, yi) log[p(xi, yi)/(p(xi)p(yi))]
```

最优τ对应AMI函数的第一个局部最小值。

#### 4.1.2 实现算法

```python
def calculate_ami(series, max_tau=50, bins=10):
    """计算平均互信息"""
    ami_values = []
    
    for tau in range(1, max_tau + 1):
        if len(series) <= tau:
            break
            
        x = series[:-tau]
        y = series[tau:]
        
        # 构建二维直方图
        hist, x_edges, y_edges = np.histogram2d(x, y, bins=bins)
        
        # 计算联合和边际概率
        joint_prob = hist / np.sum(hist)
        marginal_x = np.sum(joint_prob, axis=1)
        marginal_y = np.sum(joint_prob, axis=0)
        
        # 计算互信息
        ami = 0
        for i in range(bins):
            for j in range(bins):
                if joint_prob[i, j] > 0:
                    ami += joint_prob[i, j] * np.log(
                        joint_prob[i, j] / (marginal_x[i] * marginal_y[j] + 1e-10)
                    )
        
        ami_values.append(ami)
    
    return ami_values

def find_optimal_tau(ami_values):
    """寻找第一个局部最小值"""
    for i in range(1, len(ami_values) - 1):
        if ami_values[i] < ami_values[i-1] and ami_values[i] < ami_values[i+1]:
            return i + 1
    return 1  # 默认返回1
```

### 4.2 伪最近邻 (FNN)

#### 4.2.1 算法原理

FNN方法通过检测嵌入空间中的"假"近邻来确定最小嵌入维度。当嵌入维度不足时，原本在高维空间中距离较远的点会在低维嵌入空间中显得很近。

#### 4.2.2 判别准则

对于每个点和其最近邻，计算以下统计量：

1. **距离增长率**
   ```
   R_d+1(i) = |x_d+1(i) - x_d+1(n(i))| / R_d(i)
   ```

2. **相对方差**
   ```
   A_d+1(i) = |x_d+1(i) - x_d+1(n(i))| / σ
   ```

#### 4.2.3 实现代码

```python
def false_nearest_neighbors(series, tau, max_dim=10, rtol=15.0, atol=2.0):
    """伪最近邻算法"""
    fnn_percentages = []
    
    for dim in range(1, max_dim + 1):
        # 构建嵌入向量
        embedded = embed_series(series, dim, tau)
        
        if len(embedded) < 2:
            break
            
        # 计算最近邻
        nbrs = NearestNeighbors(n_neighbors=2).fit(embedded)
        distances, indices = nbrs.kneighbors(embedded)
        
        nearest_distances = distances[:, 1]  # 排除自身
        nearest_indices = indices[:, 1]
        
        # 检测伪近邻
        false_neighbors = 0
        total_neighbors = len(embedded)
        
        for i, nn_idx in enumerate(nearest_indices):
            if dim < max_dim:
                # 在更高维度中的距离
                higher_dim_embedded = embed_series(series, dim + 1, tau)
                if i < len(higher_dim_embedded) and nn_idx < len(higher_dim_embedded):
                    higher_distance = np.linalg.norm(
                        higher_dim_embedded[i] - higher_dim_embedded[nn_idx]
                    )
                    
                    # 应用FNN判别准则
                    if higher_distance / nearest_distances[i] > rtol:
                        false_neighbors += 1
                    
                    series_std = np.std(series)
                    if higher_distance > atol * series_std:
                        false_neighbors += 1
        
        fnn_percentage = (false_neighbors / total_neighbors) * 100
        fnn_percentages.append(fnn_percentage)
    
    return fnn_percentages

def find_optimal_dimension(fnn_percentages, threshold=5.0):
    """寻找最优嵌入维度"""
    for dim, percentage in enumerate(fnn_percentages, 1):
        if percentage < threshold:
            return dim
    return len(fnn_percentages)  # 如果没有找到，返回最大维度
```

## 5. 代理数据方法

### 5.1 FFT代理数据

保持原始数据的功率谱，破坏相位关系：

```python
def generate_fft_surrogate(data):
    """生成FFT代理数据"""
    # 计算FFT
    fft_data = np.fft.fft(data)
    
    # 随机化相位
    phases = np.random.uniform(0, 2*np.pi, len(fft_data)//2 - 1)
    
    # 构造新的复数FFT
    new_fft = np.copy(fft_data)
    new_fft[1:len(fft_data)//2] = np.abs(fft_data[1:len(fft_data)//2]) * np.exp(1j * phases)
    new_fft[len(fft_data)//2+1:] = np.conj(new_fft[1:len(fft_data)//2][::-1])
    
    # 逆FFT
    surrogate = np.real(np.fft.ifft(new_fft))
    return surrogate
```

### 5.2 AAFT代理数据

同时保持幅度分布和线性相关结构：

```python
def generate_aaft_surrogate(data):
    """生成AAFT代理数据"""
    # 步骤1：获取排序索引
    sorted_indices = np.argsort(data)
    ranks = np.argsort(sorted_indices)
    
    # 步骤2：生成高斯随机数
    gaussian_data = np.random.normal(0, 1, len(data))
    
    # 步骤3：对高斯数据进行FFT相位随机化
    fft_surrogate = generate_fft_surrogate(gaussian_data)
    
    # 步骤4：按排序替换为原始数据的值
    sorted_original = np.sort(data)
    sorted_surrogate_indices = np.argsort(fft_surrogate)
    
    surrogate = np.zeros(len(data))
    surrogate[sorted_surrogate_indices] = sorted_original
    
    return surrogate
```

### 5.3 IAAFT代理数据

迭代算法，精确保持功率谱和幅度分布：

```python
def generate_iaaft_surrogate(data, max_iterations=100, tolerance=1e-6):
    """生成IAAFT代理数据"""
    # 初始化
    original_fft = np.fft.fft(data)
    target_spectrum = np.abs(original_fft)
    sorted_original = np.sort(data)
    
    # 初始代理数据
    surrogate = generate_aaft_surrogate(data)
    
    for iteration in range(max_iterations):
        # 步骤1：保持幅度分布
        sorted_indices = np.argsort(surrogate)
        surrogate[sorted_indices] = sorted_original
        
        # 步骤2：保持功率谱
        surrogate_fft = np.fft.fft(surrogate)
        phases = np.angle(surrogate_fft)
        new_fft = target_spectrum * np.exp(1j * phases)
        surrogate = np.real(np.fft.ifft(new_fft))
        
        # 检查收敛
        current_spectrum = np.abs(np.fft.fft(surrogate))
        spectrum_error = np.mean(np.abs(current_spectrum - target_spectrum))
        
        if spectrum_error < tolerance:
            break
    
    return surrogate
```

## 6. 可视化系统

### 6.1 专业图表生成

```python
class VisualizationSuite:
    """专业可视化套件"""
    
    def __init__(self):
        plt.style.use('seaborn-v0_8-whitegrid')
        self.colors = plt.cm.Set1(np.linspace(0, 1, 10))
        
    def plot_performance_analysis(self, results, analysis_type):
        """绘制性能分析图表"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # 左图：性能曲线
        x_values = results['x_values']
        auroc_mean = results['auroc_mean']
        auroc_std = results['auroc_std']
        
        ax1.plot(x_values, auroc_mean, 'o-', linewidth=2, markersize=8)
        ax1.fill_between(x_values, 
                        auroc_mean - auroc_std, 
                        auroc_mean + auroc_std, 
                        alpha=0.3)
        
        ax1.set_xlabel(self._get_xlabel(analysis_type))
        ax1.set_ylabel('AUROC Score')
        ax1.set_title(f'CCM Performance vs {analysis_type.capitalize()}')
        ax1.grid(True, alpha=0.3)
        
        # 右图：分布箱线图
        ax2.boxplot([results[f'auroc_trial_{i}'] for i in range(len(x_values))])
        ax2.set_xlabel('Parameter Index')
        ax2.set_ylabel('AUROC Score')
        ax2.set_title('Performance Distribution')
        
        plt.tight_layout()
        return fig
```

### 6.2 三节点基序可视化

```python
def plot_motif_comparison(self, ccm_results, cte_results, system_type):
    """绘制基序分析对比图"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    motif_types = ['chain', 'fork', 'convergent']
    
    for i, motif in enumerate(motif_types):
        # CCM结果
        ax_ccm = axes[0, i]
        self._plot_confusion_matrix(ax_ccm, ccm_results[motif], f'CCM - {motif}')
        
        # CTE结果
        ax_cte = axes[1, i]
        self._plot_confusion_matrix(ax_cte, cte_results[motif], f'CTE - {motif}')
    
    plt.suptitle(f'{system_type.capitalize()} System - Motif Analysis Comparison')
    plt.tight_layout()
    return fig
```

## 7. 数值稳定性保证

### 7.1 自适应积分策略

```python
def adaptive_integration(system_func, initial_state, time_points, coupling_strength):
    """自适应积分策略"""
    # 根据耦合强度调整积分参数
    if coupling_strength > 0.8:
        rtol, atol = 1e-10, 1e-12
        max_step = min(0.01, (time_points[1] - time_points[0]) / 10)
    elif coupling_strength > 0.5:
        rtol, atol = 1e-9, 1e-11
        max_step = min(0.05, (time_points[1] - time_points[0]) / 5)
    else:
        rtol, atol = 1e-8, 1e-10
        max_step = (time_points[1] - time_points[0]) / 2
    
    try:
        solution = odeint(
            system_func, initial_state, time_points,
            rtol=rtol, atol=atol, mxstep=15000,
            hmax=max_step
        )
        
        # 检查数值稳定性
        if np.any(~np.isfinite(solution)) or np.any(np.abs(solution) > 1e6):
            raise ValueError("数值不稳定")
            
        return solution
        
    except Exception as e:
        print(f"积分失败: {e}")
        return None
```

### 7.2 分块积分处理

```python
def chunked_integration(system_func, initial_state, total_time, chunk_size=1000):
    """分块积分处理长时间序列"""
    dt = 0.01
    chunks = []
    current_state = initial_state
    
    num_chunks = int(total_time / chunk_size)
    
    for chunk in range(num_chunks):
        chunk_time = np.linspace(0, chunk_size, int(chunk_size / dt))
        
        # 集成当前块
        chunk_solution = odeint(system_func, current_state, chunk_time)
        
        # 检查稳定性
        if np.any(~np.isfinite(chunk_solution)):
            print(f"块 {chunk} 出现数值不稳定，使用恢复策略")
            current_state = recovery_strategy(current_state)
            continue
        
        chunks.append(chunk_solution[:-1])  # 避免重复最后一个点
        current_state = chunk_solution[-1]
    
    return np.vstack(chunks)

def recovery_strategy(unstable_state):
    """数值不稳定恢复策略"""
    # 重置到稳定范围内
    recovered_state = np.clip(unstable_state, -10, 10)
    recovered_state += np.random.normal(0, 0.1, recovered_state.shape)
    return recovered_state
```

## 8. 性能分析框架

### 8.1 AUROC评估

```python
def compute_auroc_with_surrogates(source, target, Dim, tau, num_surrogates=100):
    """基于代理数据的AUROC计算"""
    # 真实CCM值
    true_ccm = compute_ccm_strength(source, target, Dim, tau)
    
    # 生成代理数据的CCM值
    surrogate_ccms = []
    for _ in range(num_surrogates):
        surrogate_target = generate_mixed_surrogate(target)
        surrogate_ccm = compute_ccm_strength(source, surrogate_target, Dim, tau)
        surrogate_ccms.append(surrogate_ccm)
    
    # 计算AUROC
    true_labels = [1] * len([true_ccm]) + [0] * len(surrogate_ccms)
    all_scores = [true_ccm] + surrogate_ccms
    
    return roc_auc_score(true_labels, all_scores)
```

### 8.2 多试验统计

```python
def run_multiple_trials(system_generator, num_trials=20, **params):
    """运行多试验统计分析"""
    trial_results = []
    
    for trial in tqdm(range(num_trials), desc="Running trials"):
        # 设置随机种子保证可重现性
        np.random.seed(trial * 42)
        
        try:
            # 生成系统数据
            data = system_generator(**params)
            
            # 运行CCM分析
            result = perform_ccm_analysis(data)
            trial_results.append(result)
            
        except Exception as e:
            print(f"试验 {trial} 失败: {e}")
            continue
    
    # 计算统计量
    auroc_values = [r['auroc'] for r in trial_results if r is not None]
    
    return {
        'mean': np.mean(auroc_values),
        'std': np.std(auroc_values),
        'trials': auroc_values,
        'success_rate': len(auroc_values) / num_trials
    }
```

## 9. API参考

### 9.1 核心函数

#### `parameters(series, Dim, tau)`
构建影子流形并计算最近邻权重。

**参数:**
- `series` (array): 输入时间序列
- `Dim` (int): 嵌入维度
- `tau` (int): 时间延迟

**返回:**
- `weights` (array): 最近邻权重矩阵
- `indices` (array): 最近邻索引矩阵

#### `ccm_pearson(target, weights, indices, shadow_length)`
计算CCM强度（皮尔逊相关系数）。

**参数:**
- `target` (array): 目标时间序列
- `weights` (array): 最近邻权重
- `indices` (array): 最近邻索引
- `shadow_length` (int): 影子流形长度

**返回:**
- `correlation` (float): 皮尔逊相关系数

### 9.2 系统生成函数

#### `generate_lorenz_system(num_systems, time_steps, coupling_strength, dt=0.01)`
生成耦合Lorenz系统。

**参数:**
- `num_systems` (int): 系统数量
- `time_steps` (int): 时间步数
- `coupling_strength` (float): 耦合强度
- `dt` (float): 时间步长

**返回:**
- `systems` (array): 形状为 (num_systems, time_steps) 的数据矩阵
- `adjacency_matrix` (array): 耦合拓扑矩阵

### 9.3 分析函数

#### `run_full_analysis(system_type, analysis_type, visualizer, num_trials=20, num_surrogates=100)`
运行完整的性能分析。

**参数:**
- `system_type` (str): 系统类型
- `analysis_type` (str): 分析类型 ('length', 'degree', 'coupling', 'nodes', 'noise')
- `visualizer` (VisualizationSuite): 可视化对象
- `num_trials` (int): 试验次数
- `num_surrogates` (int): 代理数据数量

**返回:**
- 保存结果文件并生成可视化图表

### 9.4 工具函数

#### `optimize_embedding_for_system(system_type, series_length=8000)`
为指定系统优化嵌入参数。

**参数:**
- `system_type` (str): 系统类型
- `series_length` (int): 用于优化的序列长度

**返回:**
- `params` (dict): 包含最优tau和Dim的字典

---

本技术文档提供了CCM工具箱的全面技术细节。如需更多信息，请参考源代码和相关科学文献。