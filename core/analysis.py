# -*- coding: utf-8 -*-
"""
æ ¸å¿ƒåˆ†ææµç¨‹æ¨¡å— (core/analysis.py)
Core Analysis Workflow Module

åŒ…å«è¿è¡Œå•æ¬¡è¯•éªŒå’Œå®Œæ•´å¤šç»´åº¦æ€§èƒ½åˆ†æçš„å‡½æ•°ã€‚
[v3.13 Final]: æ‰©å±•äº†èŠ‚ç‚¹åˆ†æçš„èŒƒå›´ï¼Œä»¥æ¢ç©¶å°ç³»ç»Ÿçš„è¡¨ç°ã€‚
"""

import json
import os
from concurrent.futures import ProcessPoolExecutor
from datetime import datetime  # å¯¼å…¥ datetime

import numpy as np
from tqdm import tqdm
from termcolor import colored
from sklearn.metrics import roc_curve, auc

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from .systems import generate_time_series, generate_adjacency_matrix
from .ccm import (
    parameters,
    ccm_pearson,
    generate_surrogates,
    improved_ccm_confidence,
    adaptive_surrogate_testing,
    bootstrap_auroc_confidence,
)
from utils.params import optimize_embedding_for_system, adaptive_optimize_embedding_params


def _determine_worker_count(requested_workers, num_trials):
    """Return an effective worker count bounded by CPU availability and trials."""

    if num_trials <= 1:
        return 1

    if requested_workers is not None:
        return max(1, min(requested_workers, num_trials))

    cpu_total = os.cpu_count() or 1
    return max(1, min(cpu_total, num_trials))


def _run_single_trial_worker(params):
    """Wrapper to keep ProcessPool submissions picklable."""

    return run_single_trial(params)


def _execute_trials(current_params, num_trials, max_workers=None):
    """
    Run multiple trials either sequentially or in a process pool.
    
    æ”¹è¿›: ä½¿ç”¨ SeedSequence ä¸ºæ¯ä¸ªè¯•éªŒåˆ†é…ç‹¬ç«‹çš„ç§å­ï¼Œé¿å…å¤šè¿›ç¨‹ç¯å¢ƒä¸­çš„ç§å­å†²çªã€‚
    """

    worker_count = _determine_worker_count(max_workers, num_trials)

    if worker_count == 1:
        # ä¸ºå•è¿›ç¨‹æ‰§è¡Œç”Ÿæˆç‹¬ç«‹ç§å­
        base_seed = current_params.get("base_seed", None)
        if base_seed is not None:
            seed_sequence = np.random.SeedSequence(base_seed)
            trial_seeds = seed_sequence.spawn(num_trials)
            trial_params_list = []
            for i in range(num_trials):
                params = current_params.copy()
                params["trial_seed"] = trial_seeds[i]
                trial_params_list.append(params)
            return [run_single_trial(params) for params in trial_params_list]
        else:
            return [run_single_trial(current_params) for _ in range(num_trials)]

    # ä¸ºå¤šè¿›ç¨‹æ‰§è¡Œç”Ÿæˆç‹¬ç«‹ç§å­
    base_seed = current_params.get("base_seed", None)
    if base_seed is not None:
        seed_sequence = np.random.SeedSequence(base_seed)
        trial_seeds = seed_sequence.spawn(num_trials)
    else:
        # å¦‚æœæ²¡æœ‰æä¾›åŸºç¡€ç§å­ï¼Œç”Ÿæˆéšæœºç§å­åºåˆ—
        seed_sequence = np.random.SeedSequence()
        trial_seeds = seed_sequence.spawn(num_trials)

    trial_params = []
    for i in range(num_trials):
        params = current_params.copy()
        params["trial_seed"] = trial_seeds[i]
        trial_params.append(params)

    results = []

    with ProcessPoolExecutor(max_workers=worker_count) as executor:
        futures = [
            executor.submit(_run_single_trial_worker, params) for params in trial_params
        ]
        for future in futures:
            results.append(future.result())

    return results


def run_single_trial(params):
    """
    è¿è¡Œå•æ¬¡CCMå› æœåˆ†æè¯•éªŒ (æ”¹è¿›ç‰ˆ)

    æ”¹è¿›å†…å®¹:
    - ä½¿ç”¨æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•ï¼ˆKDEæˆ–ECDFæ’å€¼ï¼‰
    - å¯é€‰çš„è‡ªé€‚åº”ä»£ç†æ•°é‡æµ‹è¯•
    - Bootstrapç½®ä¿¡åŒºé—´è®¡ç®—
    - ç°ä»£åŒ–éšæœºç§å­ç®¡ç†ï¼Œæ”¯æŒç‹¬ç«‹è¯•éªŒå’Œå¯é‡ç°æ€§
    """
    # è§£åŒ…å‚æ•°
    system_type = params["system_type"]
    time_series_length = params["time_series_length"]
    num_systems = params.get("num_systems", 5)
    degree = params.get("degree", 5)
    epsilon = params.get("epsilon", 0.1)
    noise_level = params.get("noise_level", 0.0)

    Dim = params["Dim"]
    tau = params["tau"]
    num_surrogates = params.get("num_surrogates", 200)  # é»˜è®¤å¢åŠ åˆ°200
    method = params["method"]

    # æ–°å¢å‚æ•°
    use_adaptive = params.get("use_adaptive", True)  # æ˜¯å¦ä½¿ç”¨è‡ªé€‚åº”ä»£ç†æµ‹è¯•
    confidence_method = params.get("confidence_method", "kde")  # ç½®ä¿¡åº¦è®¡ç®—æ–¹æ³•
    compute_bootstrap = params.get(
        "compute_bootstrap", False
    )  # æ˜¯å¦è®¡ç®—bootstrapç½®ä¿¡åŒºé—´
    
    # ç°ä»£åŒ–éšæœºç§å­ç®¡ç†
    trial_seed = params.get("trial_seed", None)
    if trial_seed is not None:
        # å¤„ç† SeedSequence å¯¹è±¡
        if hasattr(trial_seed, 'generate_state'):
            # è¿™æ˜¯ä¸€ä¸ª SeedSequence å¯¹è±¡ï¼Œéœ€è¦ç”Ÿæˆæ•´æ•°ç§å­
            rng = np.random.default_rng(trial_seed)
            # ä¸ºå‘åå…¼å®¹æ€§ç”Ÿæˆæ•´æ•°ç§å­
            int_seed = int(trial_seed.generate_state(1)[0])
            np.random.seed(int_seed)
        else:
            # è¿™æ˜¯ä¸€ä¸ªæ•´æ•°ç§å­
            rng = np.random.default_rng(trial_seed)
            np.random.seed(trial_seed)
    else:
        # å¦‚æœæ²¡æœ‰æä¾›ç§å­ï¼Œä½¿ç”¨é»˜è®¤éšæœºçŠ¶æ€
        rng = np.random.default_rng()

    # 1. ç”Ÿæˆæ•°æ®å’Œè´¨é‡æ£€æŸ¥
    max_regeneration_attempts = 3  # æœ€å¤§é‡æ–°ç”Ÿæˆæ¬¡æ•°
    
    for attempt in range(max_regeneration_attempts):
        adjacency_matrix = generate_adjacency_matrix(num_systems, degree)
        time_series = generate_time_series(
            system_type,
            num_systems,
            adjacency_matrix,
            time_series_length,
            epsilon,
            noise_level=noise_level,
        )

        # åŸºç¡€æœ‰æ•ˆæ€§æ£€æŸ¥
        if np.any(~np.isfinite(time_series)):
            if attempt == max_regeneration_attempts - 1:
                result = {"auroc": 0.5, "scores": np.full((num_systems, num_systems), 0.5)}
                if compute_bootstrap:
                    result["bootstrap_ci"] = (0.5, 0.5)
                return result
            continue
        
        # è´¨é‡æ£€æŸ¥ï¼šæ£€æŸ¥åºåˆ—æ˜¯å¦"è¶³å¤Ÿæ··æ²Œ"
        series_quality_ok = True
        min_variance_threshold = 1e-8  # æœ€å°æ–¹å·®é˜ˆå€¼
        max_variance_ratio = 1000.0    # æœ€å¤§æ–¹å·®æ¯”é˜ˆå€¼ï¼ˆé¿å…æ•°å€¼çˆ†ç‚¸ï¼‰
        
        for i in range(num_systems):
            series_var = np.var(time_series[i])
            series_mean = np.abs(np.mean(time_series[i]))
            
            # æ£€æŸ¥æ–¹å·®æ˜¯å¦è¿‡å°ï¼ˆå¯èƒ½é™·å…¥åŒæ­¥çŠ¶æ€ï¼‰
            if series_var < min_variance_threshold:
                series_quality_ok = False
                break
                
            # æ£€æŸ¥æ–¹å·®æ˜¯å¦è¿‡å¤§ï¼ˆå¯èƒ½æ•°å€¼å‘æ•£ï¼‰
            if series_mean > 0 and series_var / (series_mean**2) > max_variance_ratio:
                series_quality_ok = False
                break
                
            # å¯¹äºæ•æ„Ÿç³»ç»Ÿï¼ˆå¦‚Henonï¼‰ï¼Œè¿›è¡Œé¢å¤–æ£€æŸ¥
            if system_type in ["henon", "noisy_henon", "henon_dynamic_noise"]:
                # æ£€æŸ¥åºåˆ—æ˜¯å¦é€€åŒ–ä¸ºå¸¸æ•°ï¼ˆHenonç³»ç»Ÿçš„å¸¸è§é—®é¢˜ï¼‰
                if np.std(time_series[i]) < 0.001:
                    series_quality_ok = False
                    break
                    
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ•°å€¼æº¢å‡º
                if np.max(np.abs(time_series[i])) > 10.0:
                    series_quality_ok = False
                    break
        
        if series_quality_ok:
            break
        elif attempt == max_regeneration_attempts - 1:
            # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æœ
            result = {"auroc": 0.5, "scores": np.full((num_systems, num_systems), 0.5)}
            if compute_bootstrap:
                result["bootstrap_ci"] = (0.5, 0.5)
            result["quality_warning"] = "Time series quality check failed after multiple attempts"
            return result

    true_causality = adjacency_matrix.T.flatten()

    # 2. è®¡ç®—CCMå’Œæ”¹è¿›çš„ç½®ä¿¡åº¦åˆ†æ•°
    scores = np.zeros((num_systems, num_systems))
    adaptive_info = {}  # å­˜å‚¨è‡ªé€‚åº”æµ‹è¯•ä¿¡æ¯

    for i in range(num_systems):
        weights, indices = parameters(time_series[i], Dim, tau)
        if weights is None:
            continue

        shadow_len = weights.shape[0]

        for j in range(num_systems):
            if i == j:
                continue

            original_coef = np.abs(
                ccm_pearson(time_series[j], weights, indices, shadow_len)
            )

            if method == "No Surrogate":
                scores[i, j] = original_coef
            else:
                if use_adaptive:
                    # ä½¿ç”¨è‡ªé€‚åº”ä»£ç†æ•°é‡æµ‹è¯•
                    confidence_score, n_surrogates_used, convergence_history = (
                        adaptive_surrogate_testing(
                            time_series[j],
                            method,
                            weights,
                            indices,
                            shadow_len,
                            min_surrogates=num_surrogates,
                            max_surrogates=min(2000, num_surrogates * 10),
                        )
                    )
                    scores[i, j] = confidence_score
                    adaptive_info[f"{i}->{j}"] = {
                        "n_surrogates_used": n_surrogates_used,
                        "convergence_history": convergence_history,
                    }
                else:
                    # ä½¿ç”¨å›ºå®šæ•°é‡çš„ä»£ç†ï¼Œä½†åº”ç”¨æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—
                    surrogates = generate_surrogates(
                        time_series[j], method, num_surrogates
                    )
                    surrogate_coefs = np.abs(
                        ccm_pearson(surrogates, weights, indices, shadow_len)
                    )

                    # ç¡®ä¿surrogate_coefsæ˜¯ä¸€ç»´æ•°ç»„
                    if surrogate_coefs.ndim == 0:
                        surrogate_coefs = np.array([surrogate_coefs])

                    confidence_score = improved_ccm_confidence(
                        original_coef, surrogate_coefs, method=confidence_method
                    )
                    scores[i, j] = confidence_score

    # 3. è®¡ç®—AUROC
    if scores.flatten().shape != true_causality.shape:
        result = {"auroc": 0.5, "scores": np.full((num_systems, num_systems), 0.5)}
        if compute_bootstrap:
            result["bootstrap_ci"] = (0.5, 0.5)
        return result

    try:
        fpr, tpr, _ = roc_curve(true_causality, scores.flatten())
        auroc = auc(fpr, tpr)

        # è®¡ç®—bootstrapç½®ä¿¡åŒºé—´ï¼ˆå¦‚æœè¯·æ±‚ï¼‰
        bootstrap_ci = None
        if compute_bootstrap:
            _, bootstrap_ci = bootstrap_auroc_confidence(
                scores.flatten(),
                true_causality,
                n_bootstrap=1000,
                confidence_level=0.95,
            )

    except ValueError:
        auroc = 0.5
        bootstrap_ci = (0.5, 0.5) if compute_bootstrap else None

    # æ„å»ºè¿”å›ç»“æœ
    result = {"auroc": auroc, "scores": scores}

    if compute_bootstrap and bootstrap_ci is not None:
        result["bootstrap_ci"] = bootstrap_ci

    if use_adaptive:
        result["adaptive_info"] = adaptive_info

    return result


def run_enhanced_analysis(
    system_type,
    analysis_type,
    visualizer,
    num_trials=20,
    num_surrogates=200,
    use_adaptive=True,
    confidence_method="kde",
    compute_bootstrap=True,
    max_workers=None,
):
    """
    è¿è¡Œå¢å¼ºç‰ˆå®Œæ•´åˆ†æï¼ŒåŒ…å«æ”¹è¿›çš„ç»Ÿè®¡æ–¹æ³•

    æ–°å¢åŠŸèƒ½:
    - è‡ªé€‚åº”ä»£ç†æ•°é‡æµ‹è¯•
    - æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—
    - Bootstrapç½®ä¿¡åŒºé—´
    - è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯è¾“å‡º
    """
    methods = ["No Surrogate", "FFT", "AAFT", "IAAFT", "Time Shift", "Random Reorder"]

    print(colored("--- [æ­¥éª¤ 1/4] æ­£åœ¨è‡ªåŠ¨ä¼˜åŒ–åµŒå…¥å‚æ•°... ---", "cyan"))
    optimal_params = optimize_embedding_for_system(system_type, series_length=8000)
    if not optimal_params:
        print(
            colored(f"é”™è¯¯: æ— æ³•ä¸º {system_type} ç³»ç»Ÿç¡®å®šæœ€ä½³å‚æ•°ã€‚åˆ†æä¸­æ­¢ã€‚", "red")
        )
        return
    print(
        colored(
            f"âœ… æœ€ä½³å‚æ•°ç¡®å®š: Dim = {optimal_params['Dim']}, tau ="
            f" {optimal_params['tau']}",
            "green",
        )
    )

    base_params = {**optimal_params}
    base_params.update({
        "system_type": system_type,
        "num_surrogates": num_surrogates,
        "use_adaptive": use_adaptive,
        "confidence_method": confidence_method,
        "compute_bootstrap": compute_bootstrap,
    })

    # ç¡®å®šåˆ†æå‚æ•°
    variable_param_name, variable_param_values, x_label, title, x_plot_values = (
        None,
        [],
        "",
        "",
        [],
    )

    if analysis_type == "length":
        base_params.update({"num_systems": 5, "degree": 5, "epsilon": 0.3})
        variable_param_name = "time_series_length"
        variable_param_values = [50, 70, 100, 150, 200]
        x_label, title = (
            "Time Series Length",
            f"Enhanced AUROC vs. Time Series Length ({system_type.capitalize()})",
        )
        x_plot_values = variable_param_values

    elif analysis_type == "degree":
        num_systems = 5
        base_params.update({
            "time_series_length": 2000, "num_systems": num_systems, "epsilon": 0.3
        })
        variable_param_name = "degree"
        degrees = [int(r * num_systems) for r in [1, 2, 4, 6, 8]]
        variable_param_values = degrees
        x_label, title = (
            "Average Degree",
            f"Enhanced AUROC vs. Average Degree ({system_type.capitalize()})",
        )
        x_plot_values = [d / (num_systems - 1) for d in degrees]

    elif analysis_type == "coupling":
        base_params.update({"time_series_length": 2000, "num_systems": 5, "degree": 5})
        variable_param_name = "epsilon"
        variable_param_values = np.linspace(0.05, 0.8, 5)
        x_label, title = (
            "Coupling Strength Îµ",
            f"Enhanced AUROC vs. Coupling Strength ({system_type.capitalize()})",
        )
        x_plot_values = variable_param_values

    elif analysis_type == "nodes":
        base_params.update({"time_series_length": 4000, "epsilon": 0.3})
        variable_param_name = "num_systems"
        variable_param_values = [3, 4, 5, 8, 12, 15]
        base_params["avg_degree"] = 2.0
        x_label, title = (
            "Number of Nodes N",
            f"Enhanced AUROC vs. Number of Nodes ({system_type.capitalize()})",
        )
        x_plot_values = variable_param_values

    elif analysis_type == "noise":
        base_params.update({
            "num_systems": 5, "degree": 5, "epsilon": 0.3, "time_series_length": 4000
        })
        variable_param_name = "noise_level"
        variable_param_values = np.linspace(0, 0.5, 5)
        x_label, title = (
            "Noise Level",
            f"Enhanced AUROC vs. Noise Level ({system_type.capitalize()})",
        )
        x_plot_values = variable_param_values
        base_params["system_type"] = system_type

    else:
        raise ValueError(f"ä¸æ”¯æŒçš„åˆ†æç±»å‹: {analysis_type}")

    print(colored("\n--- [æ­¥éª¤ 2/4] æ­£åœ¨æ‰§è¡Œå¢å¼ºç‰ˆæ€§èƒ½åˆ†æ... ---", "cyan"))
    results_raw = {m: [] for m in methods}
    bootstrap_results = {m: [] for m in methods}  # å­˜å‚¨bootstrapç½®ä¿¡åŒºé—´
    adaptive_stats = {m: [] for m in methods}  # å­˜å‚¨è‡ªé€‚åº”ç»Ÿè®¡ä¿¡æ¯

    for value in tqdm(variable_param_values, desc=f"Processing {x_label}"):
        for method in methods:
            auroc_trials_for_value = []
            bootstrap_cis_for_value = []
            adaptive_info_for_value = []

            current_params = base_params.copy()
            current_params[variable_param_name] = value
            current_params["method"] = method

            if analysis_type == "nodes":
                num_nodes = value
                degree = int(base_params["avg_degree"] * num_nodes)
                max_degree = num_nodes * (num_nodes - 1)
                current_params["degree"] = min(max_degree, degree)

            trial_results = _execute_trials(
                current_params, num_trials, max_workers=max_workers
            )

            for result in trial_results:
                auroc_trials_for_value.append(result["auroc"])

                if compute_bootstrap and "bootstrap_ci" in result:
                    bootstrap_cis_for_value.append(result["bootstrap_ci"])

                if use_adaptive and "adaptive_info" in result:
                    adaptive_info_for_value.append(result["adaptive_info"])

            results_raw[method].append(auroc_trials_for_value)

            if compute_bootstrap:
                bootstrap_results[method].append(bootstrap_cis_for_value)

            if use_adaptive:
                adaptive_stats[method].append(adaptive_info_for_value)

    # è®¡ç®—ç»Ÿè®¡é‡
    results_mean = {m: [np.mean(trials) for trials in results_raw[m]] for m in methods}
    results_std = {m: [np.std(trials) for trials in results_raw[m]] for m in methods}

    # è®¡ç®—bootstrapç½®ä¿¡åŒºé—´çš„å¹³å‡å€¼
    bootstrap_mean_cis = {}
    if compute_bootstrap:
        for method in methods:
            method_cis = []
            for value_cis in bootstrap_results[method]:
                if value_cis:  # ç¡®ä¿æœ‰æ•°æ®
                    lower_bounds = [ci[0] for ci in value_cis if ci is not None]
                    upper_bounds = [ci[1] for ci in value_cis if ci is not None]
                    if lower_bounds and upper_bounds:
                        mean_ci = (np.mean(lower_bounds), np.mean(upper_bounds))
                        method_cis.append(mean_ci)
                    else:
                        method_cis.append((0.5, 0.5))
                else:
                    method_cis.append((0.5, 0.5))
            bootstrap_mean_cis[method] = method_cis

    print(colored("\n--- [æ­¥éª¤ 3/4] æ­£åœ¨ç”Ÿæˆå¢å¼ºç‰ˆå¯è§†åŒ–å›¾è¡¨... ---", "cyan"))

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_path = f"enhanced_analysis_{system_type}_{analysis_type}_{timestamp}.png"

    # å‡†å¤‡é¢å¤–çš„ç»˜å›¾æ•°æ®
    extra_plot_data = {}
    if compute_bootstrap:
        extra_plot_data["bootstrap_cis"] = bootstrap_mean_cis

    # åˆ›å»ºå¯è§†åŒ–ï¼ˆéœ€è¦åœ¨å¯è§†åŒ–æ¨¡å—ä¸­æ·»åŠ å¯¹bootstrap CIçš„æ”¯æŒï¼‰
    visualizer.create_enhanced_performance_plot(
        x_plot_values,
        results_mean,
        results_std,
        methods,
        x_label,
        title,
        num_trials,
        save_path=save_path,
        extra_data=extra_plot_data,
        use_adaptive=use_adaptive,
        confidence_method=confidence_method,
    )

    print(colored("\n--- [æ­¥éª¤ 4/4] æ­£åœ¨ä¿å­˜è¯¦ç»†ç»“æœæ•°æ®... ---", "cyan"))

    # ä¿å­˜å¢å¼ºç‰ˆç»“æœ
    enhanced_results = {
        "metadata": {
            "system_type": system_type,
            "analysis_type": analysis_type,
            "num_trials": num_trials,
            "num_surrogates": num_surrogates,
            "use_adaptive": use_adaptive,
            "confidence_method": confidence_method,
            "compute_bootstrap": compute_bootstrap,
            "optimal_params": optimal_params,
            "timestamp": timestamp,
        },
        "x_values": x_plot_values,
        "results_mean": results_mean,
        "results_std": results_std,
        "results_raw": results_raw,
    }

    if compute_bootstrap:
        enhanced_results["bootstrap_results"] = bootstrap_mean_cis

    if use_adaptive:
        enhanced_results["adaptive_stats"] = adaptive_stats

    results_file = f"enhanced_results_{system_type}_{analysis_type}_{timestamp}.json"
    with open(results_file, "w", encoding="utf-8") as f:
        json.dump(enhanced_results, f, indent=2, ensure_ascii=False, default=str)

    print(colored(f"âœ… å¢å¼ºç‰ˆåˆ†æå®Œæˆï¼", "green"))
    print(colored(f"ğŸ“Š å¯è§†åŒ–å›¾è¡¨: {save_path}", "blue"))
    print(colored(f"ğŸ’¾ è¯¦ç»†ç»“æœ: {results_file}", "blue"))

    return enhanced_results


def run_full_analysis(
    system_type,
    analysis_type,
    visualizer,
    num_trials=20,
    num_surrogates=100,
    max_workers=None,
):
    """
    [v3.13] è¿è¡ŒæŒ‡å®šç³»ç»Ÿå’Œç±»å‹çš„å®Œæ•´å¤šç»´åº¦åˆ†æï¼Œå¹¶è‡ªåŠ¨å¤„ç†å‚æ•°ä¼˜åŒ–ã€‚
    """
    methods = ["No Surrogate", "FFT", "AAFT", "IAAFT", "Time Shift", "Random Reorder"]

    print(colored("--- [æ­¥éª¤ 1/3] æ­£åœ¨è‡ªåŠ¨ä¼˜åŒ–åµŒå…¥å‚æ•°... ---", "cyan"))
    optimal_params = optimize_embedding_for_system(system_type, series_length=8000)
    if not optimal_params:
        print(
            colored(f"é”™è¯¯: æ— æ³•ä¸º {system_type} ç³»ç»Ÿç¡®å®šæœ€ä½³å‚æ•°ã€‚åˆ†æä¸­æ­¢ã€‚", "red")
        )
        return
    print(
        colored(
            f"âœ… æœ€ä½³å‚æ•°ç¡®å®š: Dim = {optimal_params['Dim']}, tau ="
            f" {optimal_params['tau']}",
            "green",
        )
    )

    base_params = {**optimal_params}
    base_params.update({"system_type": system_type, "num_surrogates": num_surrogates})

    variable_param_name, variable_param_values, x_label, title, x_plot_values = (
        None,
        [],
        "",
        "",
        [],
    )

    if analysis_type == "length":
        base_params.update({"num_systems": 5, "degree": 5, "epsilon": 0.3})
        variable_param_name = "time_series_length"
        variable_param_values = [200, 500, 800, 1000, 1200]
        x_label, title = (
            "Time Series Length",
            f"AUROC vs. Time Series Length ({system_type.capitalize()})",
        )
        x_plot_values = variable_param_values

    elif analysis_type == "degree":
        num_systems = 5
        base_params.update({
            "time_series_length": 2000, "num_systems": num_systems, "epsilon": 0.3
        })
        variable_param_name = "degree"
        degrees = [int(r * num_systems) for r in [1, 2, 4, 6, 8]]
        variable_param_values = degrees
        x_label, title = (
            "Average Degree",
            f"AUROC vs. Average Degree ({system_type.capitalize()})",
        )
        x_plot_values = [d / (num_systems - 1) for d in degrees]

    elif analysis_type == "coupling":
        base_params.update({"time_series_length": 2000, "num_systems": 5, "degree": 5})
        variable_param_name = "epsilon"
        variable_param_values = np.linspace(0.05, 0.8, 5)
        x_label, title = (
            "Coupling Strength Îµ",
            f"AUROC vs. Coupling Strength ({system_type.capitalize()})",
        )
        x_plot_values = variable_param_values

    elif analysis_type == "nodes":
        # [v3.13] æ‰©å±•èŠ‚ç‚¹åˆ†æèŒƒå›´ä»¥åŒ…å«å°ç³»ç»Ÿ
        base_params.update({"time_series_length": 4000, "epsilon": 0.3})
        variable_param_name = "num_systems"
        variable_param_values = [3, 4, 5, 8, 12, 15]  # æ–°çš„æµ‹è¯•èŒƒå›´
        base_params["avg_degree"] = 2.0  # è®¾å®šæ¯ä¸ªèŠ‚ç‚¹å¹³å‡æœ‰2ä¸ªå…¥è¾¹
        x_label, title = (
            "Number of Nodes N",
            f"AUROC vs. Number of Nodes ({system_type.capitalize()})",
        )
        x_plot_values = variable_param_values

    elif analysis_type == "noise":
        base_params.update({
            "num_systems": 5, "degree": 5, "epsilon": 0.3, "time_series_length": 4000
        })
        variable_param_name = "noise_level"
        variable_param_values = np.linspace(0, 0.5, 5)
        x_label, title = (
            "Noise Level",
            f"AUROC vs. Noise Level ({system_type.capitalize()})",
        )
        x_plot_values = variable_param_values
        # ä¿æŒç³»ç»Ÿç±»å‹ä¸å˜ï¼Œè®©å™ªå£°åˆ†æç›´æ¥ä½¿ç”¨ä¼ å…¥çš„å™ªå£°ç³»ç»Ÿç±»å‹
        base_params["system_type"] = system_type

    else:
        raise ValueError(f"ä¸æ”¯æŒçš„åˆ†æç±»å‹: {analysis_type}")

    print(colored("\n--- [æ­¥éª¤ 2/3] æ­£åœ¨æ‰§è¡Œæ ¸å¿ƒæ€§èƒ½åˆ†æ... ---", "cyan"))
    results_raw = {m: [] for m in methods}

    for value in tqdm(variable_param_values, desc=f"Processing {x_label}"):
        
        # è‡ªé€‚åº”å‚æ•°ä¼˜åŒ–ï¼šæ ¹æ®å½“å‰å˜é‡å€¼é‡æ–°è¯„ä¼°å‚æ•°
        adaptive_params = adaptive_optimize_embedding_params(
            system_type, analysis_type, value, base_length=8000
        )
        
        # å¦‚æœè‡ªé€‚åº”ä¼˜åŒ–æˆåŠŸï¼Œä½¿ç”¨æ–°å‚æ•°
        if adaptive_params and adaptive_params != optimal_params:
            print(colored(f"ä½¿ç”¨è‡ªé€‚åº”å‚æ•° (Dim={adaptive_params['Dim']}, tau={adaptive_params['tau']}) äº {analysis_type}={value}", "blue"))
            current_base_params = base_params.copy()
            current_base_params.update(adaptive_params)
        else:
            current_base_params = base_params
        
        for method in methods:
            auroc_trials_for_value = []
            current_params = current_base_params.copy()
            current_params[variable_param_name] = value
            current_params["method"] = method

            if analysis_type == "nodes":
                num_nodes = value
                # åŠ¨æ€è®¡ç®—åº¦æ•°ä»¥ä¿æŒç½‘ç»œå¯†åº¦å¤§è‡´æ’å®š
                degree = int(base_params["avg_degree"] * num_nodes)
                # ç¡®ä¿åº¦æ•°ä¸è¶…è¿‡æœ€å¤§å¯èƒ½å€¼
                max_degree = num_nodes * (num_nodes - 1)
                current_params["degree"] = min(max_degree, degree)

            trial_results = _execute_trials(
                current_params, num_trials, max_workers=max_workers
            )

            for result in trial_results:
                # å…¼å®¹æ–°çš„è¿”å›æ ¼å¼
                if isinstance(result, dict):
                    auroc = result["auroc"]
                else:
                    # å‘åå…¼å®¹æ—§æ ¼å¼
                    auroc = result[0] if isinstance(result, tuple) else result
                auroc_trials_for_value.append(auroc)

            results_raw[method].append(auroc_trials_for_value)

    results_mean = {m: [np.mean(trials) for trials in results_raw[m]] for m in methods}
    results_std = {m: [np.std(trials) for trials in results_raw[m]] for m in methods}

    print(colored("\n--- [æ­¥éª¤ 3/3] æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å’Œç»“æœæ–‡ä»¶... ---", "cyan"))

    # [æ”¹è¿›] æ·»åŠ æ—¶é—´æˆ³ä»¥åˆ›å»ºå”¯ä¸€æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_path = f"analysis_{system_type}_{analysis_type}_{timestamp}.png"

    # [æ”¹è¿›] æå–åœ¨æœ¬æ¬¡åˆ†æä¸­ä¿æŒä¸å˜çš„å‚æ•°
    constant_params = base_params.copy()
    if variable_param_name in constant_params:
        del constant_params[variable_param_name]
    # ç§»é™¤å…¶ä»–éæ ¸å¿ƒå‚æ•°ä¿¡æ¯ï¼Œé¿å…æ ‡é¢˜è¿‡é•¿
    for key in ["system_type", "num_surrogates", "Dim", "tau", "method", "avg_degree"]:
        if key in constant_params:
            del constant_params[key]

    visualizer.create_comprehensive_performance_plot(
        x_plot_values,
        results_mean,
        results_std,
        methods,
        x_label,
        title,
        num_trials,
        save_path=save_path,
        raw_results=results_raw,
        num_surrogates=num_surrogates,
        constant_params=constant_params,  # ä¼ é€’ç»™å¯è§†åŒ–å‡½æ•°
    )

    results_data = {
        "x_values": (
            x_plot_values if isinstance(x_plot_values, list) else x_plot_values.tolist()
        ),
        "results_mean": results_mean,
        "results_std": results_std,
        "results_raw": results_raw,
        "parameters": {k: v for k, v in base_params.items() if k not in ["Dim", "tau"]},
        "embedding_params": {"Dim": base_params["Dim"], "tau": base_params["tau"]},
        "analysis_info": {
            "system_type": system_type,
            "analysis_type": analysis_type,
            "num_trials": num_trials,
            "num_surrogates": num_surrogates,
            "methods": methods,
        },
    }

    results_file = f"results_{system_type}_{analysis_type}_{timestamp}.json"
    with open(results_file, "w") as f:
        json.dump(results_data, f, indent=2)
